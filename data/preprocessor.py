# this file prepares the dataset, run only once
# used data is generated by this file
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.utils import shuffle
import warnings
warnings.filterwarnings("ignore")
warnings.warn("this will not show")
pd.set_option('display.float_format', lambda x: '%.3f' % x)


class DataPreprocessor():
    def __init__(self, data_path):
        self.df = pd.read_csv('iris.csv')

    def shuffle_data(self):
        self.df = shuffle(self.df)
        # drop the Id column, its metadata
        self.df = self.df.drop(columns=['Id'])
        print(self.df.head())

        # split features and labels
        self.x = self.df.drop(columns=['Species'])
        self.y = self.df['Species']

    def split_data(self):
        # split the data
        # %60 %40
        self.x_train, x_temp, self.y_train, y_temp = train_test_split(self.x, self.y, test_size=0.4, random_state=42)
        # %20 %20
        self.x_val, self.x_test, self.y_val, self.y_test = train_test_split(x_temp, y_temp, test_size=0.5, random_state=42)

    def scale_data(self):
        # standardization (must be done seperately in order to prevent data leakage)
        scaler = StandardScaler()
        self.x_train = scaler.fit_transform(self.x_train)
        self.x_val = scaler.transform(self.x_val)
        self.x_test = scaler.transform(self.x_test)

    def save_data(self):
        # save stationary data to csv
        pd.DataFrame(self.x_train).to_csv('x_train.csv')
        pd.DataFrame(self.x_val).to_csv('x_val.csv')
        pd.DataFrame(self.x_test).to_csv('x_test.csv')
        pd.DataFrame(self.y_train).to_csv('y_train.csv')
        pd.DataFrame(self.y_val).to_csv('y_val.csv')
        pd.DataFrame(self.y_test).to_csv('y_test.csv')

    def ready_data(self):
        self.shuffle_data()
        self.split_data()
        self.scale_data()
        self.save_data()


if __name__ == "__main__":
    data_path = 'iris.csv'
    data_prep = DataPreprocessor(data_path)
    data_prep.ready_data()

    # df = pd.read_csv('iris.csv')
    # df = shuffle(df)
    # # drop the Id column, its metadata
    # df = df.drop(columns=['Id'])
    # print(df.head())
    #
    # # split features and labels
    # x = df.drop(columns=['Species'])
    # y = df['Species']
    #
    # # split the data
    # # %60 %40
    # x_train, x_temp, y_train, y_temp = train_test_split(x, y, test_size=0.4, random_state=42)
    # # %20 %20
    # x_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, test_size=0.5, random_state=42)
    #
    # # standardization (must be done seperately in order to prevent data leakage)
    # scaler = StandardScaler()
    # x_train = scaler.fit_transform(x_train)
    # x_val = scaler.transform(x_val)
    # x_test = scaler.transform(x_test)
    #
    # pd.DataFrame(x_train).to_csv('x_train.csv')
    # pd.DataFrame(x_val).to_csv('x_val.csv')
    # pd.DataFrame(x_test).to_csv('x_test.csv')
    # pd.DataFrame(y_train).to_csv('y_train.csv')
    # pd.DataFrame(y_val).to_csv('y_val.csv')
    # pd.DataFrame(y_test).to_csv('y_test.csv')
